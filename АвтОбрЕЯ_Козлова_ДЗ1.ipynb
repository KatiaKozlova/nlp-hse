{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from fake_useragent import UserAgent\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = requests.session()\n",
    "ua = UserAgent(verify_ssl=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_names(s, db):  # find all the usernames  \n",
    "    for review in s.find_all('div', {'class': 'company-reviews-list-item'}):  # foe every review\n",
    "        # not all the reviews have a star-rating, so we check it\n",
    "        if re.search(r'<div class=\"company-reviews-list-item-ratings\">\\n </div>', review.prettify()):  # if no rating, skip it\n",
    "            continue\n",
    "        name = review.find('div', {'class': 'company-reviews-list-item-name'}).text.strip()  # find the name of the review\n",
    "        name = re.sub(r'\\t+', ' ', name)\n",
    "        if name in db_mts:\n",
    "            # they are not usernames really, just names, so we create a random number for non-unique users\n",
    "            name += '_' + str(random.randint(1, 1000))\n",
    "            db[name] = []\n",
    "        else:\n",
    "            db[name] = []\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_review(s, db):  # find all the text reviews\n",
    "    for review in s.find_all('div', {'class': 'company-reviews-list-item'}):  \n",
    "        if re.search(r'<div class=\"company-reviews-list-item-ratings\">\\n </div>', review.prettify()):  # checking if there is a rating\n",
    "            continue\n",
    "        for txt in review.find_all('div', {'class': 'company-reviews-list-item-text-message'}):  # all the texts\n",
    "            for name in db:\n",
    "                # there are pluses and minuses in review, so we collect both\n",
    "                if len(db[name]) == 0 or len(db[name]) == 1:\n",
    "                    db[name].append(txt.text.strip())\n",
    "                    break\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lables(s):  # find lables of the star-grades\n",
    "    lables = []\n",
    "    for review in s.find_all('div', {'class': 'company-reviews-list-item'}):\n",
    "        if re.search(r'<div class=\"company-reviews-list-item-ratings\">\\n </div>', review.prettify()):  # checking for rating\n",
    "            continue\n",
    "        for lable in review.find_all('span', {'class': 'company-reviews-list-item-ratings-item-label'}):  # looking for labels of grading\n",
    "            # could be 'Условия труда', 'Карьерный рост' and others\n",
    "            lable = lable.text.strip()\n",
    "            lables.append(lable)\n",
    "    lables = np.array(lables)  # put them in a special list\n",
    "    return lables.reshape(-1, 1)\n",
    "\n",
    "def find_ratings(s):  # find a rating for each lable\n",
    "    ratings = []\n",
    "    for review in s.find_all('div', {'class': 'company-reviews-list-item'}):\n",
    "        if re.search(r'<div class=\"company-reviews-list-item-ratings\">\\n </div>', review.prettify()):\n",
    "            continue\n",
    "        for rating in review.find_all('span', {'class': 'company-reviews-list-item-ratings-item-stars'}):\n",
    "            rating = rating.get('data-rating')  # there are stars: from 1 to 5\n",
    "            ratings.append(rating)\n",
    "    ratings = np.array(ratings)\n",
    "    return ratings.reshape(-1, 1)\n",
    "\n",
    "def get_stars(lab, rat, db):\n",
    "    stars = np.concatenate((lab, rat), axis=1)  # create an array \n",
    "    flag = 0  # there could be 3 or 5 criteria of grading (depending on job)\n",
    "    for i in range(len(stars)):\n",
    "        if flag:  # flag to skip the rest of criteria (they repeat)\n",
    "            flag -= 1\n",
    "            continue\n",
    "        if 'Соц.пакет:' in stars[i]:  # 3 criteria starts with 'Соц.пакет'\n",
    "            dic = {}\n",
    "            dic[stars[i][0]] = stars[i][1]\n",
    "            dic[stars[i + 1][0]] = stars[i + 1][1]\n",
    "            dic[stars[i + 2][0]] = stars[i + 2][1]\n",
    "            flag = 2\n",
    "        elif 'Коллектив:' in stars[i]:  # 5 criteria starts with 'Коллектив'\n",
    "            dic = {}\n",
    "            dic[stars[i][0]] = stars[i][1]\n",
    "            dic[stars[i + 1][0]] = stars[i + 1][1]\n",
    "            dic[stars[i + 2][0]] = stars[i + 2][1]\n",
    "            dic[stars[i + 3][0]] = stars[i + 3][1]\n",
    "            dic[stars[i + 4][0]] = stars[i + 4][1]\n",
    "            flag = 4\n",
    "        for name in db:  # add the grades to the data\n",
    "            if len(db[name]) == 2:\n",
    "                db[name].append(dic)\n",
    "                break\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitter(db):  # to divide into bad reviews and good ones\n",
    "    goods = []\n",
    "    bads = []\n",
    "    for item in db:\n",
    "        items = list(map(int, db[item][-1].values()))  # grades into integers\n",
    "        average = sum(items) / len(items)  # average grade for all the criteria\n",
    "        if average > 3:  # more than 3 -> good\n",
    "            text = db_mts[item][0] +  '\\n' + db[item][1]\n",
    "            goods.append(text)\n",
    "        elif average < 3:  # less than 3 -> bad\n",
    "            text = db_mts[item][0] +  '\\n' + db[item][1]\n",
    "            bads.append(text)\n",
    "    if len(goods) > len(bads):  # make them equal\n",
    "        goods = goods[:len(bads)]\n",
    "    else:\n",
    "        bads = bads[:len(goods)]\n",
    "    with open('good_reviews.txt', 'w', encoding='utf-8') as f_good:\n",
    "        f_good.write('\\n'.join(goods))\n",
    "    with open('bad_reviews.txt', 'w', encoding='utf-8') as f_bad:\n",
    "        f_bad.write('\\n'.join(bads))\n",
    "    return goods, bads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checker(word):  # checker for digits and punctuation\n",
    "    for char in string.punctuation:\n",
    "        if char in word:\n",
    "            return False\n",
    "    for char in string.digits:\n",
    "        if char in word:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tokenizer(text):  # tokenizer...\n",
    "    tokenized = []\n",
    "    for part in text:\n",
    "        words = []\n",
    "        tokenized_part = word_tokenize(part)  # tokenize\n",
    "        for word in tokenized_part:\n",
    "            if checker(word):\n",
    "                word = word.lower()  # make lower\n",
    "                word = morph.parse(word)[0].normal_form  # to normal form\n",
    "                words.append(word)\n",
    "        tokenized.append(words)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dic(tokenized_text, good_or_bad):  # frequency dictionary of the tokens\n",
    "    good_tokens = {}\n",
    "    bad_tokens = {}\n",
    "    for index, part in enumerate(tokenized_text):\n",
    "        for token in part:\n",
    "            if good_or_bad[index] == 1:\n",
    "                if token not in good_tokens:\n",
    "                    good_tokens[token] = 1\n",
    "                else:\n",
    "                    good_tokens[token] += 1\n",
    "            else:\n",
    "                if token not in bad_tokens:\n",
    "                    bad_tokens[token] = 1\n",
    "                else:\n",
    "                    bad_tokens[token] += 1\n",
    "    good_tokens = dict(sorted(good_tokens.items(), key=lambda item: item[1], reverse=True))  # good dictionary sorting\n",
    "    bad_tokens = dict(sorted(bad_tokens.items(), key=lambda item: item[1], reverse=True))  # bad dictionary sorting\n",
    "    good_vals = set(good_tokens.keys())  # all the good tokens\n",
    "    bad_vals = set(bad_tokens.keys())  # # all the bad tokens\n",
    "    return good_tokens, bad_tokens, good_vals, bad_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_small(words, dictionary):  # delete non-frequent tokens\n",
    "    real_words = []\n",
    "    for word in words:\n",
    "        if dictionary[word] > 2:  # occurrence is more than 2\n",
    "            real_words.append(word)\n",
    "    return real_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cкачиваем дату:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Искользуем краулер (всего 70 страниц, так как дальше начинаются выбросы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db_mts = {}\n",
    "for i in range(2, 71):\n",
    "    url = f'https://pravda-sotrudnikov.ru/company/mts-3?page={i}'\n",
    "    req = session.get(url, headers={'User-Agent': ua.random})\n",
    "    page = req.text\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    db_mts = find_names(soup, db_mts)\n",
    "    db_mts = find_review(soup, db_mts)\n",
    "    db_mts = get_stars(find_lables(soup), find_ratings(soup), db_mts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем полученную базу данных в файл типа JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(db_mts, file, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делим отзывы на положительные и отрицательные (т.к. оценка колеблется между 1 и 5, 3 мы не учитываем)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_reviews, bad_reviews = splitter(db_mts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем список всех отзывов и список \"правильных\" значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = good_reviews + bad_reviews\n",
    "y = np.concatenate((np.full((len(good_reviews),), 1), np.full((len(bad_reviews),), 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Токенизируем слова, приводим их к нижнему регистру и к начальной форме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = tokenizer(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делим выборку на тренировочную и тестовую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем словари и множества слов, встречающихся в плохих и хороших отзывах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_dic, bad_dic, good_words, bad_words = create_dic(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Составляем 2 множества: \n",
    "в одном слова, которые встречаются только в положительных отзывах, а в другом - встречающиеся только в отрицательных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_good = good_words.difference(bad_words)\n",
    "only_bad = bad_words.difference(good_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Исключаем шум (слишком малочастотные слова):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "really_bad = del_small(only_bad, bad_dic)\n",
    "really_good = del_small(only_good, good_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создаем функцию, которая будет определять, положительный ли отзыв или отрицательный в зависимости от того, какие слова встретились в нём:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_or_bad_checker(test, good, bad):\n",
    "    preds = []\n",
    "    for review in test:\n",
    "        for_good = 0\n",
    "        for_bad = 0\n",
    "        for token in review:\n",
    "            if token in good:\n",
    "                for_good += 1\n",
    "            elif token in bad:\n",
    "                for_bad += 1\n",
    "        if for_good > for_bad:\n",
    "            preds.append(1)\n",
    "        elif for_bad > for_good:\n",
    "            preds.append(0)\n",
    "        else:\n",
    "            preds.append(random.randint(0, 1))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = good_or_bad_checker(X_test, really_good, really_bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Считаем качество при помощи *accuracy*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7410714285714286"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 способа улучшить эту программу:\n",
    "1. посмотреть не на токены, а на их сочетания (биграммы)\n",
    "2. попробовать отследить все *не* и менять следующие слова на их антонимы\n",
    "3. можно проставить веса и не убирать те вхождения, которые встречаются как в положительных, так и в отрицательных отзывах, но в одном типе намного чаще"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем первый способ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dic_bigrams(tokenized_text, good_or_bad):  # frequency dictionary of the bigrams\n",
    "    good_dic = {}\n",
    "    bad_dic = {}\n",
    "    for index, part in enumerate(tokenized_text):\n",
    "        for token_id in range(len(part) - 1):\n",
    "            bigram = part[token_id] + ' ' + part[token_id + 1]\n",
    "            if good_or_bad[index] == 1:\n",
    "                if bigram not in good_dic:\n",
    "                    good_dic[bigram] = 1\n",
    "                else:\n",
    "                    good_dic[bigram] += 1\n",
    "            else:\n",
    "                if bigram not in bad_dic:\n",
    "                    bad_dic[bigram] = 1\n",
    "                else:\n",
    "                    bad_dic[bigram] += 1\n",
    "    good_dic = dict(sorted(good_dic.items(), key=lambda item: item[1], reverse=True))  # good dictionary sorting\n",
    "    bad_dic = dict(sorted(bad_dic.items(), key=lambda item: item[1], reverse=True))  # bad dictionary sorting\n",
    "    good_vals_bigrams = set(good_dic.keys())  # all the good bigrams\n",
    "    bad_vals_bigrams = set(bad_dic.keys())  # # all the bad bigrams\n",
    "    return good_dic, bad_dic, good_vals_bigrams, bad_vals_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_dic_bigrams, bad_dic_bigrams, good_bigrams, bad_bigrams = create_dic_bigrams(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_good_bigrams = good_bigrams.difference(bad_bigrams)\n",
    "only_bad_bigrams = bad_bigrams.difference(good_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "really_bad_bigrams = del_small(only_bad_bigrams, bad_dic_bigrams)\n",
    "really_good_bigrams = del_small(only_good_bigrams, good_dic_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def good_or_bad_checker_bigrams(test, good, bad):\n",
    "    preds = []\n",
    "    for review in test:\n",
    "        for_good = 0\n",
    "        for_bad = 0\n",
    "        for token_id in range(len(review) - 1):\n",
    "            bigram = review[token_id] + ' ' + review[token_id + 1]\n",
    "            if bigram in good:\n",
    "                for_good += 1\n",
    "            elif bigram in bad:\n",
    "                for_bad += 1\n",
    "        if for_good > for_bad:\n",
    "            preds.append(1)\n",
    "        elif for_bad > for_good:\n",
    "            preds.append(0)\n",
    "        else:\n",
    "            preds.append(random.randint(0, 1))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_bigram = good_or_bad_checker_bigrams(X_test, really_good_bigrams, really_bad_bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И... результат стал хуже (но немного). Возможно, потому что корпус недостаточно большой для биграмм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7232142857142857"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_preds_bigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зато можно сделать лучше при помощи TF-IDF!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(texts):\n",
    "    preprocessed = []\n",
    "    one = {}\n",
    "    for t in texts:\n",
    "        tokens = word_tokenize(t)  # tokenize\n",
    "        lemmatized = ' '.join([morph.parse(item)[0].normal_form for item in tokens if item.isalpha()])  # lemmatize\n",
    "        preprocessed.append(lemmatized)\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = good_reviews + bad_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(X_tfidf, y, test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vec.fit_transform(preprocessing(X_train_tfidf))\n",
    "X_test_tfidf = tfidf_vec.transform(preprocessing(X_test_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train_tfidf)\n",
    "y_preds_tfidf = clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8660714285714286"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test_tfidf, y_preds_tfidf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
